
# 爬虫

   ```python
   import requests
   # 示例
url = "http://baidu.com"
resp = requests.get(url,params= ,headers= ,...)
resp = requests.post(url,datas=    )
resp.encoding = '' # 有时候会出现乱码

```

```python
# 正则
import re
obj = re.compile('正则表达式',re.S) #re.S指的是可以匹配换行符
# 例子 r'<img alt="(?P<name>.*?)" src="(?P<src>.*?)" />'
resultiter = obj.finditer()
for iter in resultiter:
	iter.group("")
```

```python
 import csv
 #csv 文件用于储存数据，可以直接write(list)  写入之后默认  元素间以逗号链接
 csvwriter = csv.open()
 csvwriter.writerrow(list)
```

```python
import bs4
page = bs4.BeautifulSoup("url","html.parser")
table = page.find("div",class_="")
table = page.find("div",attrs={"class":""})
```

```python
import lxml 
parser=etree.HTMLParser()
parser=etree.XMLParser()
tree = etree.parse("filepath"，parser=parser)
tree = etree.XML("str")
tree = etree.HTML("str")

result = tree.xpath('/html') #
result = tree.xpath('/html/body/a/text()') #获取a标签的内容
result = tree.xpath('/html/div/a/@href')  #获取属性值
result = tree.xpath('/html//a')  #//搜所有子节点
result = tree.xpath('/html/div/*/a') #通配符
result = tree.xpath('/html/div/a[@href='']/text()')  #从属性限制标签


result = result.xpath('./')  #从当前标签开始寻找，  ./代表当前标签



#列表生成式，去除所有空格换行符，去除空字符串
result=[text.strip() for text in result if text.strip()]  

 
```
